# ScalableETL

ğŸ§© OgÃ³lna koncepcja projektu

Celem projektu jest zaprojektowanie i przetestowanie skalowalnej architektury procesu ETL (Extract â€“ Transform â€“ Load) dziaÅ‚ajÄ…cej w Å›rodowisku chmurowym.
Nie skupia siÄ™ on na przetwarzaniu konkretnego typu danych, lecz na inÅ¼ynierii i wydajnoÅ›ci caÅ‚ego pipelineâ€™u â€“ jego odpornoÅ›ci, elastycznoÅ›ci i moÅ¼liwoÅ›ci automatycznego skalowania.

ğŸ¯ ZaÅ‚oÅ¼enia projektu

Projekt ma pokazaÄ‡, jak nowoczesne narzÄ™dzia chmurowe (takie jak Docker, Kubernetes, Azure Data Factory czy Apache Airflow) mogÄ… wspÃ³Å‚pracowaÄ‡ w celu budowy skalowalnego systemu przetwarzania danych.

ğŸ” Zakres badaÅ„ i testÃ³w

W ramach realizacji projektu analizowane sÄ… nastÄ™pujÄ…ce aspekty dziaÅ‚ania systemu:

SkalowalnoÅ›Ä‡ â€“ jak pipeline reaguje na zwiÄ™kszenie iloÅ›ci danych wejÅ›ciowych (np. wzrost rozmiaru plikÃ³w CSV lub liczby rekordÃ³w).

RÃ³wnolegÅ‚oÅ›Ä‡ zadaÅ„ â€“ testy zachowania systemu przy jednoczesnym uruchamianiu wielu procesÃ³w ETL.

Automatyczne skalowanie (Auto-Scaling) â€“ w jaki sposÃ³b Kubernetes (Horizontal Pod Autoscaler) zwiÄ™ksza liczbÄ™ replik kontenerÃ³w przy wzroÅ›cie obciÄ…Å¼enia i jak szybko reaguje na zmiany.

Monitorowanie i metryki â€“ implementacja systemu obserwowalnoÅ›ci z wykorzystaniem Prometheus i Grafana do pomiaru wydajnoÅ›ci, obciÄ…Å¼enia CPU/RAM oraz czasu przetwarzania danych.

ğŸ§  Kluczowy cel

Projekt ma charakter badawczo-inÅ¼ynierski â€“ jego gÅ‚Ã³wnym rezultatem jest:

praktyczna demonstracja dziaÅ‚ania skalowalnego procesu ETL w Å›rodowisku konteneryzowanym,

analiza wpÅ‚ywu konfiguracji i parametrÃ³w klastra na efektywnoÅ›Ä‡ przetwarzania,

dokumentacja wynikÃ³w i rekomendacji dotyczÄ…cych optymalizacji pipelineâ€™Ã³w danych.
